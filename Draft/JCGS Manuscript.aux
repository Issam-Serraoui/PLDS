\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{Johansen1988}
\citation{Friston2003a}
\citation{Xie2013a}
\citation{Kalman1963}
\citation{Kalman1960a}
\citation{Ljung1998}
\citation{Hsieh2013,Banerjee2013a}
\citation{CHEN1989}
\citation{Zaharia2010}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}{section.1}}
\@writefile{brf}{\backcite{Johansen1988}{{2}{1}{section.1}}}
\@writefile{brf}{\backcite{Friston2003a}{{2}{1}{section.1}}}
\@writefile{brf}{\backcite{Xie2013a}{{2}{1}{section.1}}}
\@writefile{brf}{\backcite{Kalman1963}{{2}{1}{section.1}}}
\@writefile{brf}{\backcite{Kalman1960a}{{2}{1}{section.1}}}
\@writefile{brf}{\backcite{Ljung1998}{{2}{1}{section.1}}}
\citation{rabiner1989tutorial}
\@writefile{brf}{\backcite{Hsieh2013}{{3}{1}{section.1}}}
\@writefile{brf}{\backcite{Banerjee2013a}{{3}{1}{section.1}}}
\@writefile{brf}{\backcite{CHEN1989}{{3}{1}{section.1}}}
\@writefile{brf}{\backcite{Zaharia2010}{{3}{1}{section.1}}}
\@writefile{brf}{\backcite{rabiner1989tutorial}{{3}{1}{section.1}}}
\@writefile{toc}{\contentsline {section}{\numberline {2}The Model}{4}{section.2}}
\newlabel{eq:genericssm}{{1}{5}{The Model}{equation.2.1}{}}
\citation{roweis1999unifying}
\@writefile{brf}{\backcite{roweis1999unifying}{{7}{2}{equation.2.1}}}
\newlabel{eq:model0}{{2}{7}{The Model}{equation.2.2}{}}
\newlabel{eqn:penaltylik}{{3}{7}{The Model}{equation.2.3}{}}
\citation{shumway1982approach}
\citation{ghahramani1996parameter}
\citation{van1994n4sid,doretto2003dynamic}
\citation{bootslearning}
\@writefile{toc}{\contentsline {section}{\numberline {3}Parameter Estimation}{8}{section.3}}
\@writefile{brf}{\backcite{shumway1982approach}{{8}{3}{section.3}}}
\@writefile{brf}{\backcite{ghahramani1996parameter}{{8}{3}{section.3}}}
\@writefile{brf}{\backcite{van1994n4sid}{{8}{3}{section.3}}}
\@writefile{brf}{\backcite{doretto2003dynamic}{{8}{3}{section.3}}}
\@writefile{brf}{\backcite{bootslearning}{{8}{3}{section.3}}}
\newlabel{eqn:loglik}{{4}{9}{Parameter Estimation}{equation.3.4}{}}
\newlabel{eqn:penaltylik2}{{5}{10}{Parameter Estimation}{equation.3.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}E Step}{10}{subsection.3.1}}
\newlabel{eq:expecs}{{6}{10}{E Step}{equation.3.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}M Step}{10}{subsection.3.2}}
\citation{turlach2005simultaneous}
\citation{tikhonov1943stability}
\newlabel{eq:updateR}{{7}{11}{M Step}{equation.3.7}{}}
\@writefile{brf}{\backcite{turlach2005simultaneous}{{11}{3.2}{equation.3.7}}}
\@writefile{brf}{\backcite{tikhonov1943stability}{{11}{3.2}{equation.3.7}}}
\newlabel{eq:updatec}{{8}{11}{M Step}{equation.3.8}{}}
\citation{beck2009fast}
\@writefile{brf}{\backcite{beck2009fast}{{12}{3.2}{equation.3.8}}}
\newlabel{eq:updatea}{{9}{12}{M Step}{equation.3.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Initialization}{12}{subsection.3.3}}
\newlabel{sec:initial}{{3.3}{12}{Initialization}{subsection.3.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces The Complete EM Algorithm\relax }}{13}{table.caption.2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:em}{{1}{13}{The Complete EM Algorithm\relax }{table.caption.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Improving Computational Efficiency}{13}{subsection.3.4}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Simulations}{14}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Simulation Setup}{14}{subsection.4.1}}
\newlabel{sec:simsetup}{{4.1}{14}{Simulation Setup}{subsection.4.1}{}}
\newlabel{eq:distance}{{10}{14}{Simulation Setup}{equation.4.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces $x$ axis is tuning parameter $\lambda _C$ under log scale and $y$ axis is the distance between truth and estimations; $\lambda _A$ is increasing proportionally with $\lambda _C$. One can see that in both the low dimensional and hight dimensional setting, estimation accuracies for $A$ and $C$ first increase then decrease as penalty increases.\relax }}{15}{figure.caption.3}}
\newlabel{fig:low-high-d-sim}{{1}{15}{$x$ axis is tuning parameter $\lambda _C$ under log scale and $y$ axis is the distance between truth and estimations; $\lambda _A$ is increasing proportionally with $\lambda _C$. One can see that in both the low dimensional and hight dimensional setting, estimation accuracies for $A$ and $C$ first increase then decrease as penalty increases.\relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Low dimensional setting}}}{15}{figure.caption.3}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {High dimensional setting}}}{15}{figure.caption.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Estimation and prediction accuracies. The $x$-axis represents the penalty size on a $\qopname  \relax o{log}$ scale. The $y$-axis represents the estimation and prediction accuracies. Note that the penalty which yields the most accurate estimation also gives the best prediction.\relax }}{16}{figure.caption.4}}
\newlabel{fig:estpredaccuracy}{{2}{16}{Estimation and prediction accuracies. The $x$-axis represents the penalty size on a $\log $ scale. The $y$-axis represents the estimation and prediction accuracies. Note that the penalty which yields the most accurate estimation also gives the best prediction.\relax }{figure.caption.4}{}}
\citation{landman2011multi}
\citation{smith2004advances}
\citation{van2013wu,moeller2010multiband,feinberg2010multiplexed}
\citation{van2013wu}
\@writefile{toc}{\contentsline {section}{\numberline {5}Application}{17}{section.5}}
\newlabel{sec:application}{{5}{17}{Application}{section.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Data and Motivation}{17}{subsection.5.1}}
\@writefile{brf}{\backcite{landman2011multi}{{17}{5.1}{subsection.5.1}}}
\@writefile{brf}{\backcite{smith2004advances}{{17}{5.1}{subsection.5.1}}}
\@writefile{brf}{\backcite{van2013wu}{{17}{5.1}{subsection.5.1}}}
\@writefile{brf}{\backcite{moeller2010multiband}{{17}{5.1}{subsection.5.1}}}
\@writefile{brf}{\backcite{feinberg2010multiplexed}{{17}{5.1}{subsection.5.1}}}
\@writefile{brf}{\backcite{van2013wu}{{17}{5.1}{subsection.5.1}}}
\citation{zhu2006automatic}
\citation{amari1996new}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Results}{18}{subsection.5.2}}
\@writefile{brf}{\backcite{zhu2006automatic}{{18}{5.2}{subsection.5.2}}}
\@writefile{brf}{\backcite{amari1996new}{{18}{5.2}{subsection.5.2}}}
\citation{nebel2014disruption}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Similarities Among Estimated $A$ Matrices\relax }}{19}{table.caption.5}}
\newlabel{tab:similarity}{{2}{19}{Similarities Among Estimated $A$ Matrices\relax }{table.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Similarities among the four estimated $A$ matrices. The distance $d(\cdot ,\cdot )$ was used in this figure. The two off-diagonal pixels that have the minimum distances, i.e. the red pixel and the orange pixel, correspond to the pairs of $(A_{11},A_{12})$ and $(A_{21},A_{22})$ respectively. With this similarity map, one can tell which two scans are from the same subject.\relax }}{19}{figure.3}}
\newlabel{fig:matsim}{{3}{19}{Similarities among the four estimated $A$ matrices. The distance $d(\cdot ,\cdot )$ was used in this figure. The two off-diagonal pixels that have the minimum distances, i.e. the red pixel and the orange pixel, correspond to the pairs of $(A_{11},A_{12})$ and $(A_{21},A_{22})$ respectively. With this similarity map, one can tell which two scans are from the same subject.\relax }{figure.3}{}}
\@writefile{brf}{\backcite{nebel2014disruption}{{19}{5.2}{figure.3}}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces 3D rendering of columns of matrix $C_{11}$: estimation for the first scan of subject one.\relax }}{20}{figure.4}}
\newlabel{fig:3d}{{4}{20}{3D rendering of columns of matrix $C_{11}$: estimation for the first scan of subject one.\relax }{figure.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Comparison of prediction accuracies on HCP data. \emph  {Left:} Accuracies of {\sc  \texttt  {Mr}.\nobreakspace  {}\texttt  {Sid}}\nobreakspace  {}and SVD predictions over time, with accuracy measured through mean squared error (MSE). \emph  {Right:} Sample time series plot. The dotted green curve represents the $60\%$ confidence band given by the {\sc  \texttt  {Mr}.\nobreakspace  {}\texttt  {Sid}}\nobreakspace  {}model. The true time series consists of averaged signals from a subsample of voxels. The predictions were also averaged over the same subsample. The confidence band was estimated based on the covariance matrix of these voxels. A subsample of 20 voxels were selected for this experiment, to avoid the calculation of large covariance matrices. All values were log-scaled for plotting purposes. \relax }}{21}{figure.5}}
\citation{allen2014generalized}
\citation{arbabshirani2014impact}
\newlabel{fig:predaccy}{{5}{22}{Comparison of prediction accuracies on HCP data. \emph {Left:} Accuracies of \mrsid ~and SVD predictions over time, with accuracy measured through mean squared error (MSE). \emph {Right:} Sample time series plot. The dotted green curve represents the $60\%$ confidence band given by the \mrsid ~model. The true time series consists of averaged signals from a subsample of voxels. The predictions were also averaged over the same subsample. The confidence band was estimated based on the covariance matrix of these voxels. A subsample of 20 voxels were selected for this experiment, to avoid the calculation of large covariance matrices. All values were log-scaled for plotting purposes. \relax }{figure.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Discussion}{22}{section.6}}
\@writefile{brf}{\backcite{allen2014generalized}{{22}{6}{section.6}}}
\bibstyle{Chicago}
\bibdata{reference}
\bibcite{allen2014generalized}{{1}{2014}{{Allen et~al.}}{{Allen, Grosenick, and Taylor}}}
\bibcite{amari1996new}{{2}{1996}{{Amari et~al.}}{{Amari, Cichocki, Yang, et~al.}}}
\bibcite{arbabshirani2014impact}{{3}{2014}{{Arbabshirani et~al.}}{{Arbabshirani, Damaraju, Phlypo, Plis, Allen, Ma, Mathalon, Preda, Vaidya, Adali, et~al.}}}
\bibcite{Banerjee2013a}{{4}{2013}{{Banerjee et~al.}}{{Banerjee, Vogelstein, and Dunson}}}
\@writefile{brf}{\backcite{arbabshirani2014impact}{{23}{6}{section.6}}}
\bibcite{beck2009fast}{{5}{2009}{{Beck and Teboulle}}{{Beck and Teboulle}}}
\bibcite{bootslearning}{{6}{Boots}{{Boots}}{{}}}
\bibcite{CHEN1989}{{7}{1989}{{CHEN et~al.}}{{CHEN, BILLINGS, and LUO}}}
\bibcite{doretto2003dynamic}{{8}{2003}{{Doretto et~al.}}{{Doretto, Chiuso, Wu, and Soatto}}}
\bibcite{feinberg2010multiplexed}{{9}{2010}{{Feinberg et~al.}}{{Feinberg, Moeller, Smith, Auerbach, Ramanna, Gunther, Glasser, Miller, Ugurbil, and Yacoub}}}
\bibcite{Friston2003a}{{10}{2003}{{Friston et~al.}}{{Friston, Harrison, and Penny}}}
\bibcite{ghahramani1996parameter}{{11}{1996}{{Ghahramani and Hinton}}{{Ghahramani and Hinton}}}
\bibcite{Hsieh2013}{{12}{2013}{{Hsieh et~al.}}{{Hsieh, Sustik, Dhillon, Ravikumar, and Poldrack}}}
\bibcite{Johansen1988}{{13}{1988}{{Johansen}}{{Johansen}}}
\bibcite{Kalman1960a}{{14}{1960}{{Kalman}}{{Kalman}}}
\bibcite{Kalman1963}{{15}{1963}{{Kalman}}{{Kalman}}}
\bibcite{landman2011multi}{{16}{2011}{{Landman et~al.}}{{Landman, Huang, Gifford, Vikram, Lim, Farrell, Bogovic, Hua, Chen, Jarso, et~al.}}}
\bibcite{Ljung1998}{{17}{1998}{{Ljung}}{{Ljung}}}
\bibcite{moeller2010multiband}{{18}{2010}{{Moeller et~al.}}{{Moeller, Yacoub, Olman, Auerbach, Strupp, Harel, and U{\u {g}}urbil}}}
\bibcite{nebel2014disruption}{{19}{2014}{{Nebel et~al.}}{{Nebel, Joel, Muschelli, Barber, Caffo, Pekar, and Mostofsky}}}
\bibcite{rabiner1989tutorial}{{20}{1989}{{Rabiner}}{{Rabiner}}}
\bibcite{roweis1999unifying}{{21}{1999}{{Roweis and Ghahramani}}{{Roweis and Ghahramani}}}
\bibcite{shumway1982approach}{{22}{1982}{{Shumway and Stoffer}}{{Shumway and Stoffer}}}
\bibcite{smith2004advances}{{23}{2004}{{Smith et~al.}}{{Smith, Jenkinson, Woolrich, Beckmann, Behrens, Johansen-Berg, Bannister, De~Luca, Drobnjak, Flitney, et~al.}}}
\bibcite{tikhonov1943stability}{{24}{1943}{{Tikhonov}}{{Tikhonov}}}
\bibcite{turlach2005simultaneous}{{25}{2005}{{Turlach et~al.}}{{Turlach, Venables, and Wright}}}
\bibcite{van2013wu}{{26}{2013}{{Van~Essen et~al.}}{{Van~Essen, Smith, Barch, Behrens, Yacoub, Ugurbil, Consortium, et~al.}}}
\bibcite{van1994n4sid}{{27}{1994}{{Van~Overschee and De~Moor}}{{Van~Overschee and De~Moor}}}
\bibcite{Xie2013a}{{28}{2013}{{Xie et~al.}}{{Xie, Huang, and Willett}}}
\bibcite{Zaharia2010}{{29}{2010}{{Zaharia et~al.}}{{Zaharia, Chowdhury, Franklin, Shenker, and Stoica}}}
\bibcite{zhu2006automatic}{{30}{2006}{{Zhu and Ghodsi}}{{Zhu and Ghodsi}}}
