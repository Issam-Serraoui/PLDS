\relax 
\citation{Johansen1988}
\citation{Friston2003a}
\citation{Xie2013a}
\citation{Kalman1963}
\citation{Kalman1960a}
\citation{Ljung1998}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}}
\citation{Hsieh2013,Banerjee2013a}
\citation{CHEN1989}
\citation{Zaharia2010}
\citation{rabiner1989tutorial}
\@writefile{toc}{\contentsline {section}{\numberline {2}The Model}{4}}
\newlabel{eq:model}{{3}{5}{The Model}{}{}}
\citation{roweis1999unifying}
\citation{roweis1999unifying}
\newlabel{eq:model0}{{4}{8}{The Model}{}{}}
\newlabel{eqn:penaltylik}{{5}{8}{The Model}{}{}}
\newlabel{eqn:penaltylikdual}{{6}{8}{The Model}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Parameter Estimation}{8}}
\citation{shumway1982approach}
\citation{ghahramani1996parameter}
\citation{van1994n4sid,doretto2003dynamic}
\citation{bootslearning}
\newlabel{eqn:loglik}{{7}{10}{Parameter Estimation}{}{}}
\newlabel{eqn:penaltylik2}{{8}{10}{Parameter Estimation}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}E Step}{10}}
\newlabel{eq:expecs}{{9}{11}{E Step}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}M Step}{11}}
\newlabel{eq:updateR}{{10}{11}{M Step}{}{}}
\citation{turlach2005simultaneous}
\citation{tikhonov1943stability}
\newlabel{eq:penaltylik1}{{11}{12}{M Step}{}{}}
\newlabel{eq:vectorizec}{{12}{12}{M Step}{}{}}
\newlabel{eq:penaltylik11}{{13}{12}{M Step}{}{}}
\citation{beck2009fast}
\citation{daubechies2004iterative}
\newlabel{eq:updatec}{{14}{13}{M Step}{}{}}
\newlabel{eq:penaltylik2}{{15}{13}{M Step}{}{}}
\newlabel{eq:penaltylik21}{{16}{13}{M Step}{}{}}
\newlabel{eq:updatea}{{17}{14}{M Step}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Initialization}{14}}
\newlabel{sec:initial}{{3.3}{14}{Initialization}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}The Complete EM}{14}}
\newlabel{sec:em}{{3.4}{14}{The Complete EM}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Improving Computational Efficiency}{14}}
\citation{landman2011multi}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces The Complete EM Algorithm\relax }}{15}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:em}{{1}{15}{The Complete EM Algorithm\relax }{}{}}
\citation{van2013wu,moeller2010multiband,feinberg2010multiplexed}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6}The Data}{16}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Results}{16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Parameter Estimation}{16}}
\newlabel{sec:lowdsim}{{4.1}{16}{Parameter Estimation}{}{}}
\citation{kuhn1955hungarian}
\newlabel{eq:distance}{{18}{17}{Parameter Estimation}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces x axis is tuning parameter $\lambda _C$ under log scale and y axis is the distance between truth and estimations; $\lambda _A$ is increasing proportionally with $\lambda _C$. One can see that in both the low dimensional and hight dimensional setting, estimation accuracies for $A$ and $C$ first increase then decrease as penalty increases.\relax }}{18}}
\newlabel{fig:low-high-d-sim}{{1}{18}{x axis is tuning parameter $\lambda _C$ under log scale and y axis is the distance between truth and estimations; $\lambda _A$ is increasing proportionally with $\lambda _C$. One can see that in both the low dimensional and hight dimensional setting, estimation accuracies for $A$ and $C$ first increase then decrease as penalty increases.\relax }{}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Low dimensional setting}}}{18}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {High dimensional setting}}}{18}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Row 1: A truth; non-penalized estimation of A; optimally penalized estimation of A. Row 2: C truth; non-penalized estimation of C; optimally penalized estimation of C.\relax }}{19}}
\newlabel{fig:heatmap}{{2}{19}{Row 1: A truth; non-penalized estimation of A; optimally penalized estimation of A. Row 2: C truth; non-penalized estimation of C; optimally penalized estimation of C.\relax }{}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces {\sc  \texttt  {Mr}.\nobreakspace  {}\texttt  {Sid}}\nobreakspace  {}Running Time\relax }}{20}}
\newlabel{tab:runningTime}{{2}{20}{\mrsid ~Running Time\relax }{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Making Predictions}{20}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Application}{20}}
\newlabel{sec:application}{{5}{20}{Application}{}{}}
\citation{smith2004advances}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Estimation and prediction accuracies. The x-axis is the penalty size under log scale, while y-axis is the estimation and prediction accuracies. One can see that the penalty that yields the most accurate estimation also gives the best predictions.\relax }}{21}}
\newlabel{fig:estpredaccuracy}{{3}{21}{Estimation and prediction accuracies. The x-axis is the penalty size under log scale, while y-axis is the estimation and prediction accuracies. One can see that the penalty that yields the most accurate estimation also gives the best predictions.\relax }{}{}}
\citation{zhu2006automatic}
\citation{amari1996new}
\citation{nebel2014disruption}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Similarities Among Estimated $A$ Matrices\relax }}{23}}
\newlabel{tab:similarity}{{3}{23}{Similarities Among Estimated $A$ Matrices\relax }{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces 3D rendering of columns of matrix $C$: estimation from the first scan of subject one shown in this plot.\relax }}{23}}
\newlabel{fig:3d}{{4}{23}{3D rendering of columns of matrix $C$: estimation from the first scan of subject one shown in this plot.\relax }{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Prediction accuracies comparison on HCP data. \emph  {Left:} The mean squared error (MSE) is used as the accuracy measure. \emph  {Right:} Sample time series plot. The dotted green curve stands for the $60\%$ confidence band given by {\sc  \texttt  {Mr}.\nobreakspace  {}\texttt  {Sid}}\nobreakspace  {}model. The true time series is averaged signals from a subsample of voxels. The predictions are also averaged over the same subsample. The confidence band is estimated based on the covariance matrix of these voxels. A subsample of 20 voxels are picked in this experiment to avoid big covariance matrices calculation. All values are log-scaled for plotting purpose. \relax }}{24}}
\newlabel{fig:predaccy}{{5}{24}{Prediction accuracies comparison on HCP data. \emph {Left:} The mean squared error (MSE) is used as the accuracy measure. \emph {Right:} Sample time series plot. The dotted green curve stands for the $60\%$ confidence band given by \mrsid ~model. The true time series is averaged signals from a subsample of voxels. The predictions are also averaged over the same subsample. The confidence band is estimated based on the covariance matrix of these voxels. A subsample of 20 voxels are picked in this experiment to avoid big covariance matrices calculation. All values are log-scaled for plotting purpose. \relax }{}{}}
\citation{allen2014generalized}
\citation{arbabshirani2014impact}
\bibstyle{Chicago}
\bibdata{reference}
\bibcite{allen2014generalized}{{1}{2014}{{Allen et~al.}}{{Allen, Grosenick, and Taylor}}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Discussion}{25}}
\bibcite{amari1996new}{{2}{1996}{{Amari et~al.}}{{Amari, Cichocki, Yang, et~al.}}}
\bibcite{arbabshirani2014impact}{{3}{2014}{{Arbabshirani et~al.}}{{Arbabshirani, Damaraju, Phlypo, Plis, Allen, Ma, Mathalon, Preda, Vaidya, Adali, et~al.}}}
\bibcite{Banerjee2013a}{{4}{2013}{{Banerjee et~al.}}{{Banerjee, Vogelstein, and Dunson}}}
\bibcite{beck2009fast}{{5}{2009}{{Beck and Teboulle}}{{Beck and Teboulle}}}
\bibcite{bootslearning}{{6}{Boots}{{Boots}}{{}}}
\bibcite{CHEN1989}{{7}{1989}{{CHEN et~al.}}{{CHEN, BILLINGS, and LUO}}}
\bibcite{daubechies2004iterative}{{8}{2004}{{Daubechies et~al.}}{{Daubechies, Defrise, and De~Mol}}}
\bibcite{doretto2003dynamic}{{9}{2003}{{Doretto et~al.}}{{Doretto, Chiuso, Wu, and Soatto}}}
\bibcite{feinberg2010multiplexed}{{10}{2010}{{Feinberg et~al.}}{{Feinberg, Moeller, Smith, Auerbach, Ramanna, Gunther, Glasser, Miller, Ugurbil, and Yacoub}}}
\bibcite{Friston2003a}{{11}{2003}{{Friston et~al.}}{{Friston, Harrison, and Penny}}}
\bibcite{ghahramani1996parameter}{{12}{1996}{{Ghahramani and Hinton}}{{Ghahramani and Hinton}}}
\bibcite{Hsieh2013}{{13}{2013}{{Hsieh et~al.}}{{Hsieh, Sustik, Dhillon, Ravikumar, and Poldrack}}}
\bibcite{Johansen1988}{{14}{1988}{{Johansen}}{{Johansen}}}
\bibcite{Kalman1960a}{{15}{1960}{{Kalman}}{{Kalman}}}
\bibcite{Kalman1963}{{16}{1963}{{Kalman}}{{Kalman}}}
\bibcite{kuhn1955hungarian}{{17}{1955}{{Kuhn}}{{Kuhn}}}
\bibcite{landman2011multi}{{18}{2011}{{Landman et~al.}}{{Landman, Huang, Gifford, Vikram, Lim, Farrell, Bogovic, Hua, Chen, Jarso, et~al.}}}
\bibcite{Ljung1998}{{19}{1998}{{Ljung}}{{Ljung}}}
\bibcite{moeller2010multiband}{{20}{2010}{{Moeller et~al.}}{{Moeller, Yacoub, Olman, Auerbach, Strupp, Harel, and U{\u {g}}urbil}}}
\bibcite{nebel2014disruption}{{21}{2014}{{Nebel et~al.}}{{Nebel, Joel, Muschelli, Barber, Caffo, Pekar, and Mostofsky}}}
\bibcite{rabiner1989tutorial}{{22}{1989}{{Rabiner}}{{Rabiner}}}
\bibcite{roweis1999unifying}{{23}{1999}{{Roweis and Ghahramani}}{{Roweis and Ghahramani}}}
\bibcite{shumway1982approach}{{24}{1982}{{Shumway and Stoffer}}{{Shumway and Stoffer}}}
\bibcite{smith2004advances}{{25}{2004}{{Smith et~al.}}{{Smith, Jenkinson, Woolrich, Beckmann, Behrens, Johansen-Berg, Bannister, De~Luca, Drobnjak, Flitney, et~al.}}}
\bibcite{tikhonov1943stability}{{26}{1943}{{Tikhonov}}{{Tikhonov}}}
\bibcite{turlach2005simultaneous}{{27}{2005}{{Turlach et~al.}}{{Turlach, Venables, and Wright}}}
\bibcite{van2013wu}{{28}{2013}{{Van~Essen et~al.}}{{Van~Essen, Smith, Barch, Behrens, Yacoub, Ugurbil, Consortium, et~al.}}}
\bibcite{van1994n4sid}{{29}{1994}{{Van~Overschee and De~Moor}}{{Van~Overschee and De~Moor}}}
\bibcite{Xie2013a}{{30}{2013}{{Xie et~al.}}{{Xie, Huang, and Willett}}}
\bibcite{Zaharia2010}{{31}{2010}{{Zaharia et~al.}}{{Zaharia, Chowdhury, Franklin, Shenker, and Stoica}}}
\bibcite{zhu2006automatic}{{32}{2006}{{Zhu and Ghodsi}}{{Zhu and Ghodsi}}}
